{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras tutorial - the Happy House\n",
    "\n",
    "Welcome to the first assignment of week 2. In this assignment, you will:\n",
    "1. Learn to use Keras, a high-level neural networks API (programming framework), written in Python and capable of running on top of several lower-level frameworks including TensorFlow and CNTK. \n",
    "2. See how you can in a couple of hours build a deep learning algorithm.\n",
    "\n",
    "Why are we using Keras? Keras was developed to enable deep learning engineers to build and experiment with different models very quickly. Just as TensorFlow is a higher-level framework than Python, Keras is an even higher-level framework and provides additional abstractions. Being able to go from idea to result with the least possible delay is key to finding good models. However, Keras is more restrictive than the lower-level frameworks, so there are some very complex models that you can implement in TensorFlow but not (without more difficulty) in Keras. That being said, Keras will work fine for many common models. \n",
    "\n",
    "In this exercise, you'll work on the \"Happy House\" problem, which we'll explain below. Let's load the required packages and solve the problem of the Happy House!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from kt_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: As you can see, we've imported a lot of functions from Keras. You can use them easily just by calling them directly in the notebook. Ex: `X = Input(...)` or `X = ZeroPadding2D(...)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - The Happy House \n",
    "\n",
    "For your next vacation, you decided to spend a week with five of your friends from school. It is a very convenient house with many things to do nearby. But the most important benefit is that everybody has commited to be happy when they are in the house. So anyone wanting to enter the house must prove their current state of happiness.\n",
    "\n",
    "<img src=\"images/happy-house.jpg\" style=\"width:350px;height:270px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 1** </u><font color='purple'>  : **the Happy House**</center></caption>\n",
    "\n",
    "\n",
    "As a deep learning expert, to make sure the \"Happy\" rule is strictly applied, you are going to build an algorithm which that uses pictures from the front door camera to check if the person is happy or not. The door should open only if the person is happy. \n",
    "\n",
    "You have gathered pictures of your friends and yourself, taken by the front-door camera. The dataset is labbeled. \n",
    "\n",
    "<img src=\"images/house-members.png\" style=\"width:550px;height:250px;\">\n",
    "\n",
    "Run the following code to normalize the dataset and learn about its shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 64, 64, 3) (1, 600) (150, 64, 64, 3) (1, 150) [0 1]\n",
      "[[[[178 190 163]\n",
      "   [172 181 173]\n",
      "   [188 196 184]\n",
      "   ...\n",
      "   [255 255 254]\n",
      "   [254 255 250]\n",
      "   [249 253 222]]\n",
      "\n",
      "  [[184 201 165]\n",
      "   [149 154 142]\n",
      "   [149 158 139]\n",
      "   ...\n",
      "   [255 255 253]\n",
      "   [254 255 250]\n",
      "   [251 255 230]]\n",
      "\n",
      "  [[198 207 165]\n",
      "   [141 147 128]\n",
      "   [168 184 154]\n",
      "   ...\n",
      "   [253 255 244]\n",
      "   [254 255 248]\n",
      "   [253 255 233]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 77  82  89]\n",
      "   [ 60  64  68]\n",
      "   [ 49  53  55]\n",
      "   ...\n",
      "   [ 31  32  30]\n",
      "   [ 47  48  46]\n",
      "   [ 75  75  75]]\n",
      "\n",
      "  [[ 68  71  76]\n",
      "   [ 55  58  59]\n",
      "   [ 44  47  47]\n",
      "   ...\n",
      "   [ 30  31  29]\n",
      "   [ 40  41  39]\n",
      "   [ 63  64  63]]\n",
      "\n",
      "  [[ 61  64  66]\n",
      "   [ 52  54  54]\n",
      "   [ 45  47  46]\n",
      "   ...\n",
      "   [ 30  31  29]\n",
      "   [ 38  38  36]\n",
      "   [ 56  56  54]]]\n",
      "\n",
      "\n",
      " [[[193 204 168]\n",
      "   [188 203 155]\n",
      "   [215 227 181]\n",
      "   ...\n",
      "   [219 215 208]\n",
      "   [191 185 170]\n",
      "   [173 165 142]]\n",
      "\n",
      "  [[201 213 182]\n",
      "   [200 214 169]\n",
      "   [204 215 164]\n",
      "   ...\n",
      "   [254 254 252]\n",
      "   [224 231 222]\n",
      "   [201 212 184]]\n",
      "\n",
      "  [[204 213 178]\n",
      "   [211 220 184]\n",
      "   [207 215 175]\n",
      "   ...\n",
      "   [242 248 240]\n",
      "   [200 219 197]\n",
      "   [184 204 176]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[167 185 199]\n",
      "   [135 149 174]\n",
      "   [118 127 147]\n",
      "   ...\n",
      "   [ 36  31  28]\n",
      "   [ 36  31  28]\n",
      "   [ 34  31  27]]\n",
      "\n",
      "  [[139 154 179]\n",
      "   [115 126 145]\n",
      "   [104 111 125]\n",
      "   ...\n",
      "   [ 35  30  27]\n",
      "   [ 35  30  27]\n",
      "   [ 37  33  29]]\n",
      "\n",
      "  [[119 130 149]\n",
      "   [104 110 124]\n",
      "   [ 93  98 108]\n",
      "   ...\n",
      "   [ 34  29  26]\n",
      "   [ 33  29  25]\n",
      "   [ 37  33  29]]]\n",
      "\n",
      "\n",
      " [[[ 82  97  50]\n",
      "   [ 77  92  58]\n",
      "   [ 82  93  62]\n",
      "   ...\n",
      "   [112 128  74]\n",
      "   [126 144  86]\n",
      "   [118 134  78]]\n",
      "\n",
      "  [[ 69  79  48]\n",
      "   [ 79  89  58]\n",
      "   [ 89  98  68]\n",
      "   ...\n",
      "   [116 134  78]\n",
      "   [119 136  83]\n",
      "   [114 129  77]]\n",
      "\n",
      "  [[ 77  83  54]\n",
      "   [ 79  84  58]\n",
      "   [ 82  88  62]\n",
      "   ...\n",
      "   [126 142  84]\n",
      "   [119 132  84]\n",
      "   [126 139  97]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 30  34  25]\n",
      "   [ 37  40  29]\n",
      "   [ 29  35  27]\n",
      "   ...\n",
      "   [ 14  14  11]\n",
      "   [ 14  14  12]\n",
      "   [ 13  14  11]]\n",
      "\n",
      "  [[ 45  47  33]\n",
      "   [ 38  42  32]\n",
      "   [ 35  41  32]\n",
      "   ...\n",
      "   [ 13  13  11]\n",
      "   [ 13  13  11]\n",
      "   [ 13  13  11]]\n",
      "\n",
      "  [[ 43  46  32]\n",
      "   [ 36  41  32]\n",
      "   [ 58  60  46]\n",
      "   ...\n",
      "   [ 13  13  11]\n",
      "   [ 12  13  11]\n",
      "   [ 13  13  10]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[204 195 158]\n",
      "   [215 205 173]\n",
      "   [212 206 166]\n",
      "   ...\n",
      "   [255 255 254]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[212 200 163]\n",
      "   [217 207 170]\n",
      "   [210 203 167]\n",
      "   ...\n",
      "   [255 255 253]\n",
      "   [254 254 254]\n",
      "   [233 240 239]]\n",
      "\n",
      "  [[216 208 170]\n",
      "   [204 195 160]\n",
      "   [219 215 177]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [250 250 248]\n",
      "   [215 221 219]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 253]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [105  71  49]\n",
      "   [110  76  52]\n",
      "   [112  77  52]]\n",
      "\n",
      "  [[255 255 247]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 97  67  47]\n",
      "   [102  70  49]\n",
      "   [103  71  49]]\n",
      "\n",
      "  [[255 255 252]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 88  61  44]\n",
      "   [ 92  64  45]\n",
      "   [ 95  66  45]]]\n",
      "\n",
      "\n",
      " [[[245 249 239]\n",
      "   [251 253 247]\n",
      "   [245 249 239]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[245 249 235]\n",
      "   [249 253 238]\n",
      "   [244 250 234]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[229 240 216]\n",
      "   [235 243 218]\n",
      "   [234 242 224]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[253 254 239]\n",
      "   [182 196 155]\n",
      "   [123 145 102]\n",
      "   ...\n",
      "   [ 60  67  62]\n",
      "   [ 63  70  64]\n",
      "   [ 67  75  67]]\n",
      "\n",
      "  [[254 254 237]\n",
      "   [191 202 173]\n",
      "   [121 142 100]\n",
      "   ...\n",
      "   [ 56  61  57]\n",
      "   [ 59  65  59]\n",
      "   [ 62  69  62]]\n",
      "\n",
      "  [[254 254 230]\n",
      "   [197 208 178]\n",
      "   [119 141  98]\n",
      "   ...\n",
      "   [ 51  57  52]\n",
      "   [ 54  60  55]\n",
      "   [ 58  64  57]]]\n",
      "\n",
      "\n",
      " [[[252 253 248]\n",
      "   [254 255 252]\n",
      "   [254 254 253]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[250 252 245]\n",
      "   [251 253 246]\n",
      "   [252 253 247]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[247 249 239]\n",
      "   [237 240 226]\n",
      "   [245 246 233]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[254 255 244]\n",
      "   [255 255 249]\n",
      "   [255 255 246]\n",
      "   ...\n",
      "   [234 245 192]\n",
      "   [230 234 198]\n",
      "   [233 238 200]]\n",
      "\n",
      "  [[254 255 247]\n",
      "   [255 255 248]\n",
      "   [254 254 227]\n",
      "   ...\n",
      "   [247 250 226]\n",
      "   [240 245 214]\n",
      "   [228 236 193]]\n",
      "\n",
      "  [[254 255 242]\n",
      "   [255 255 250]\n",
      "   [254 254 238]\n",
      "   ...\n",
      "   [248 248 233]\n",
      "   [236 242 194]\n",
      "   [230 238 186]]]] [[0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1\n",
      "  0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1\n",
      "  0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0\n",
      "  1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1\n",
      "  1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0\n",
      "  0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1\n",
      "  0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0\n",
      "  1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1\n",
      "  1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0\n",
      "  1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1\n",
      "  0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1\n",
      "  0 0 1 1 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1\n",
      "  1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 0\n",
      "  1 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1\n",
      "  1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      "  1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1\n",
      "  0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0]] [[[[223 207 159]\n",
      "   [217 208 156]\n",
      "   [222 217 169]\n",
      "   ...\n",
      "   [255 255 253]\n",
      "   [255 255 253]\n",
      "   [255 255 253]]\n",
      "\n",
      "  [[218 204 154]\n",
      "   [215 202 165]\n",
      "   [218 210 172]\n",
      "   ...\n",
      "   [255 255 253]\n",
      "   [255 255 253]\n",
      "   [255 255 253]]\n",
      "\n",
      "  [[202 189 146]\n",
      "   [207 194 152]\n",
      "   [226 218 188]\n",
      "   ...\n",
      "   [254 255 251]\n",
      "   [253 254 249]\n",
      "   [255 255 253]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[227 230 196]\n",
      "   [248 249 233]\n",
      "   [255 255 253]\n",
      "   ...\n",
      "   [106  68  43]\n",
      "   [108  68  43]\n",
      "   [110  71  46]]\n",
      "\n",
      "  [[235 237 206]\n",
      "   [250 250 235]\n",
      "   [255 255 253]\n",
      "   ...\n",
      "   [102  65  41]\n",
      "   [105  66  41]\n",
      "   [107  68  42]]\n",
      "\n",
      "  [[227 231 187]\n",
      "   [240 242 218]\n",
      "   [255 255 252]\n",
      "   ...\n",
      "   [ 99  62  39]\n",
      "   [102  64  40]\n",
      "   [104  65  40]]]\n",
      "\n",
      "\n",
      " [[[205 217 178]\n",
      "   [194 209 162]\n",
      "   [224 236 197]\n",
      "   ...\n",
      "   [181 170 154]\n",
      "   [173 161 142]\n",
      "   [166 155 133]]\n",
      "\n",
      "  [[204 215 185]\n",
      "   [198 213 166]\n",
      "   [215 226 178]\n",
      "   ...\n",
      "   [228 226 220]\n",
      "   [193 191 173]\n",
      "   [184 178 153]]\n",
      "\n",
      "  [[203 215 180]\n",
      "   [208 220 174]\n",
      "   [210 219 171]\n",
      "   ...\n",
      "   [244 248 244]\n",
      "   [206 221 204]\n",
      "   [197 212 183]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[180 201 194]\n",
      "   [143 158 185]\n",
      "   [125 135 157]\n",
      "   ...\n",
      "   [ 37  33  30]\n",
      "   [ 37  33  30]\n",
      "   [ 37  34  30]]\n",
      "\n",
      "  [[148 165 192]\n",
      "   [123 134 157]\n",
      "   [109 116 132]\n",
      "   ...\n",
      "   [ 35  31  28]\n",
      "   [ 37  33  30]\n",
      "   [ 38  34  30]]\n",
      "\n",
      "  [[129 142 164]\n",
      "   [108 116 133]\n",
      "   [ 97 102 114]\n",
      "   ...\n",
      "   [ 35  31  28]\n",
      "   [ 35  31  28]\n",
      "   [ 37  33  30]]]\n",
      "\n",
      "\n",
      " [[[177 161 115]\n",
      "   [198 189 133]\n",
      "   [199 193 145]\n",
      "   ...\n",
      "   [164 136 118]\n",
      "   [150 122 104]\n",
      "   [160 131 105]]\n",
      "\n",
      "  [[184 176 122]\n",
      "   [206 202 141]\n",
      "   [197 195 145]\n",
      "   ...\n",
      "   [242 215 167]\n",
      "   [227 198 153]\n",
      "   [206 176 135]]\n",
      "\n",
      "  [[180 172 129]\n",
      "   [175 170 125]\n",
      "   [171 165 122]\n",
      "   ...\n",
      "   [251 234 187]\n",
      "   [249 227 175]\n",
      "   [252 227 172]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 33  29  18]\n",
      "   [ 38  33  22]\n",
      "   [ 40  35  23]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 32  27  17]\n",
      "   [ 37  31  21]\n",
      "   [ 38  33  21]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [249 249 248]\n",
      "   ...\n",
      "   [ 31  27  17]\n",
      "   [ 35  30  20]\n",
      "   [ 37  32  21]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[218 227 186]\n",
      "   [212 223 173]\n",
      "   [240 246 208]\n",
      "   ...\n",
      "   [215 207 193]\n",
      "   [198 188 166]\n",
      "   [193 179 153]]\n",
      "\n",
      "  [[225 232 203]\n",
      "   [223 232 185]\n",
      "   [228 236 187]\n",
      "   ...\n",
      "   [249 250 246]\n",
      "   [227 231 216]\n",
      "   [219 220 195]]\n",
      "\n",
      "  [[224 232 195]\n",
      "   [230 237 195]\n",
      "   [227 234 189]\n",
      "   ...\n",
      "   [243 249 240]\n",
      "   [216 230 210]\n",
      "   [215 228 200]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[206 222 208]\n",
      "   [161 174 199]\n",
      "   [142 150 171]\n",
      "   ...\n",
      "   [ 34  29  26]\n",
      "   [ 38  33  29]\n",
      "   [ 40  35  31]]\n",
      "\n",
      "  [[170 184 208]\n",
      "   [140 150 171]\n",
      "   [123 128 144]\n",
      "   ...\n",
      "   [ 35  31  27]\n",
      "   [ 37  32  29]\n",
      "   [ 42  37  33]]\n",
      "\n",
      "  [[147 158 179]\n",
      "   [122 128 143]\n",
      "   [111 115 126]\n",
      "   ...\n",
      "   [ 37  33  29]\n",
      "   [ 38  34  30]\n",
      "   [ 41  36  32]]]\n",
      "\n",
      "\n",
      " [[[179 154 108]\n",
      "   [178 159 109]\n",
      "   [169 151 104]\n",
      "   ...\n",
      "   [247 247 189]\n",
      "   [246 246 168]\n",
      "   [247 247 172]]\n",
      "\n",
      "  [[173 147 100]\n",
      "   [195 175 116]\n",
      "   [190 177 119]\n",
      "   ...\n",
      "   [251 251 199]\n",
      "   [252 252 187]\n",
      "   [250 250 182]]\n",
      "\n",
      "  [[201 161 116]\n",
      "   [203 174 119]\n",
      "   [196 183 118]\n",
      "   ...\n",
      "   [248 247 188]\n",
      "   [252 251 191]\n",
      "   [251 251 191]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[117 119  85]\n",
      "   [137 136  90]\n",
      "   [132 135  97]\n",
      "   ...\n",
      "   [ 97  93  70]\n",
      "   [ 96  88  67]\n",
      "   [119 108  66]]\n",
      "\n",
      "  [[115 113  78]\n",
      "   [121 121  89]\n",
      "   [117 121  84]\n",
      "   ...\n",
      "   [ 71  66  50]\n",
      "   [ 77  70  53]\n",
      "   [105  94  74]]\n",
      "\n",
      "  [[128 123  86]\n",
      "   [179 173 140]\n",
      "   [146 140 101]\n",
      "   ...\n",
      "   [ 88  79  61]\n",
      "   [105  97  70]\n",
      "   [ 69  59  56]]]\n",
      "\n",
      "\n",
      " [[[203 219 180]\n",
      "   [195 213 173]\n",
      "   [210 226 191]\n",
      "   ...\n",
      "   [119 114 109]\n",
      "   [103  99  96]\n",
      "   [ 90  87  84]]\n",
      "\n",
      "  [[176 192 156]\n",
      "   [180 197 153]\n",
      "   [201 218 176]\n",
      "   ...\n",
      "   [157 149 136]\n",
      "   [148 139 122]\n",
      "   [142 132 114]]\n",
      "\n",
      "  [[183 199 167]\n",
      "   [184 200 155]\n",
      "   [187 200 154]\n",
      "   ...\n",
      "   [197 202 195]\n",
      "   [171 176 155]\n",
      "   [150 151 131]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[156 177 208]\n",
      "   [136 152 184]\n",
      "   [121 134 163]\n",
      "   ...\n",
      "   [ 28  25  23]\n",
      "   [ 32  29  27]\n",
      "   [ 34  31  28]]\n",
      "\n",
      "  [[129 146 178]\n",
      "   [120 133 161]\n",
      "   [106 115 138]\n",
      "   ...\n",
      "   [ 31  27  25]\n",
      "   [ 32  29  26]\n",
      "   [ 36  32  30]]\n",
      "\n",
      "  [[115 129 156]\n",
      "   [105 115 138]\n",
      "   [ 94 102 120]\n",
      "   ...\n",
      "   [ 31  27  25]\n",
      "   [ 32  28  26]\n",
      "   [ 37  33  30]]]] [[1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1\n",
      "  0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
      "  0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 1\n",
      "  0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1\n",
      "  0 1 0 1 1 0]] [0 1]\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "print(X_train_orig.shape, Y_train_orig.shape, X_test_orig.shape, Y_test_orig.shape, classes )\n",
    "print (X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Reshape\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Details of the \"Happy\" dataset**:\n",
    "- Images are of shape (64,64,3)\n",
    "- Training: 600 pictures\n",
    "- Test: 150 pictures\n",
    "\n",
    "It is now time to solve the \"Happy\" Challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Building a model in Keras\n",
    "\n",
    "Keras is very good for rapid prototyping. In just a short time you will be able to build a model that achieves outstanding results.\n",
    "\n",
    "Here is an example of a model in Keras:\n",
    "\n",
    "```python\n",
    "def model(input_shape):\n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
    "    \n",
    "    return model\n",
    "```\n",
    "\n",
    "Note that Keras uses a different convention with variable names than we've previously used with numpy and TensorFlow. In particular, rather than creating and assigning a new variable on each step of forward propagation such as `X`, `Z1`, `A1`, `Z2`, `A2`, etc. for the computations for the different layers, in Keras code each line above just reassigns `X` to a new value using `X = ...`. In other words, during each step of forward propagation, we are just writing the latest value in the commputation into the same variable `X`. The only exception was `X_input`, which we kept separate and did not overwrite, since we needed it at the end to create the Keras model instance (`model = Model(inputs = X_input, ...)` above). \n",
    "\n",
    "**Exercise**: Implement a `HappyModel()`. This assignment is more open-ended than most. We suggest that you start by implementing a model using the architecture we suggest, and run through the rest of this assignment using that as your initial model. But after that, come back and take initiative to try out other model architectures. For example, you might take inspiration from the model above, but then vary the network architecture and hyperparameters however you wish. You can also use other functions such as `AveragePooling2D()`, `GlobalMaxPooling2D()`, `Dropout()`. \n",
    "\n",
    "**Note**: You have to be careful with your data's shapes. Use what you've learned in the videos to make sure your convolutional, pooling and fully-connected layers are adapted to the volumes you're applying it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: HappyModel\n",
    "\n",
    "def HappyModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the HappyModel.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Feel free to use the suggested outline in the text above to get started, and run through the whole\n",
    "    # exercise (including the later portions of this notebook) once. The come back also try out other\n",
    "    # network architectures as well. \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (7, 7), strides=(1, 1), name='conv0')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    print(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs=X_input, outputs=X, name='HappyModel')\n",
    "\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now built a function to describe your model. To train and test this model, there are four steps in Keras:\n",
    "1. Create the model by calling the function above\n",
    "2. Compile the model by calling `model.compile(optimizer = \"...\", loss = \"...\", metrics = [\"accuracy\"])`\n",
    "3. Train the model on train data by calling `model.fit(x = ..., y = ..., epochs = ..., batch_size = ...)`\n",
    "4. Test the model on test data by calling `model.evaluate(x = ..., y = ...)`\n",
    "\n",
    "If you want to know more about `model.compile()`, `model.fit()`, `model.evaluate()` and their arguments, refer to the official [Keras documentation](https://keras.io/models/model/).\n",
    "\n",
    "**Exercise**: Implement step 1, i.e. create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_4/Relu:0\", shape=(?, 64, 64, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (1 line)\n",
    "happyModel = HappyModel(X_train.shape[1:])\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement step 2, i.e. compile the model to configure the learning process. Choose the 3 arguments of `compile()` wisely. Hint: the Happy Challenge is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (1 line)\n",
    "happyModel.compile('adam' , 'binary_crossentropy' , metrics=['accuracy'])\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement step 3, i.e. train the model. Choose the number of epochs and the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.1918 - acc: 0.5500\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 776us/step - loss: 0.5064 - acc: 0.7817\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 749us/step - loss: 0.3169 - acc: 0.8483\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 779us/step - loss: 0.2244 - acc: 0.9333\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 780us/step - loss: 0.1308 - acc: 0.9500\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 749us/step - loss: 0.1103 - acc: 0.9600\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 773us/step - loss: 0.0904 - acc: 0.9717\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 783us/step - loss: 0.0771 - acc: 0.9783\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 774us/step - loss: 0.0697 - acc: 0.9817\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 749us/step - loss: 0.0976 - acc: 0.9650\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 752us/step - loss: 0.0777 - acc: 0.9750 0s - loss: 0.0831 - acc: 0.97\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 778us/step - loss: 0.0704 - acc: 0.9800\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 791us/step - loss: 0.0585 - acc: 0.9867 0s - loss: 0.0681 - acc: 0.980 - ETA: 0s - loss: 0.0756 - acc: 0\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 764us/step - loss: 0.0551 - acc: 0.9867\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 751us/step - loss: 0.0577 - acc: 0.9833\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 793us/step - loss: 0.0449 - acc: 0.9850\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 762us/step - loss: 0.0481 - acc: 0.9850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 750us/step - loss: 0.0372 - acc: 0.9900\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 778us/step - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 751us/step - loss: 0.0327 - acc: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d10780e10>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START CODE HERE ### (1 line)\n",
    "happyModel.fit( X_train , Y_train ,epochs=20, batch_size =50)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you run `fit()` again, the `model` will continue to train with the parameters it has already learnt instead of reinitializing them.\n",
    "\n",
    "**Exercise**: Implement step 4, i.e. test/evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 881us/step\n",
      "\n",
      "Loss = 0.13916799227396648\n",
      "Test Accuracy = 0.9466666579246521\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (1 line)\n",
    "preds = happyModel.evaluate(X_test,Y_test,batch_size=40 , verbose=1 , sample_weight=None)\n",
    "### END CODE HERE ###\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your `happyModel()` function worked, you should have observed much better than random-guessing (50%) accuracy on the train and test sets.\n",
    "\n",
    "To give you a point of comparison, our model gets around **95% test accuracy in 40 epochs** (and 99% train accuracy) with a mini batch size of 16 and \"adam\" optimizer. But our model gets decent accuracy after just 2-5 epochs, so if you're comparing different models you can also train a variety of models on just a few epochs and see how they compare. \n",
    "\n",
    "If you have not yet achieved a very good accuracy (let's say more than 80%), here're some things you can play around with to try to achieve it:\n",
    "\n",
    "- Try using blocks of CONV->BATCHNORM->RELU such as:\n",
    "```python\n",
    "X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv0')(X)\n",
    "X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "X = Activation('relu')(X)\n",
    "```\n",
    "until your height and width dimensions are quite low and your number of channels quite large (≈32 for example). You are encoding useful information in a volume with a lot of channels. You can then flatten the volume and use a fully-connected layer.\n",
    "- You can use MAXPOOL after such blocks. It will help you lower the dimension in height and width.\n",
    "- Change your optimizer. We find Adam works well. \n",
    "- If the model is struggling to run and you get memory issues, lower your batch_size (12 is usually a good compromise)\n",
    "- Run on more epochs, until you see the train accuracy plateauing. \n",
    "\n",
    "Even if you have achieved a good accuracy, please feel free to keep playing with your model to try to get even better results. \n",
    "\n",
    "**Note**: If you perform hyperparameter tuning on your model, the test set actually becomes a dev set, and your model might end up overfitting to the test (dev) set. But just for the purpose of this assignment, we won't worry about that here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Conclusion\n",
    "\n",
    "Congratulations, you have solved the Happy House challenge! \n",
    "\n",
    "Now, you just need to link this model to the front-door camera of your house. We unfortunately won't go into the details of how to do that here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**What we would like you to remember from this assignment:**\n",
    "- Keras is a tool we recommend for rapid prototyping. It allows you to quickly try out different model architectures. Are there any applications of deep learning to your daily life that you'd like to implement using Keras? \n",
    "- Remember how to code a model in Keras and the four steps leading to the evaluation of your model on the test set. Create->Compile->Fit/Train->Evaluate/Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Test with your own image (Optional)\n",
    "\n",
    "Congratulations on finishing this assignment. You can now take a picture of your face and see if you could enter the Happy House. To do that:\n",
    "    1. Click on \"File\" in the upper bar of this notebook, then click \"Open\" to go on your Coursera Hub.\n",
    "    2. Add your image to this Jupyter Notebook's directory, in the \"images\" folder\n",
    "    3. Write your image's name in the following code\n",
    "    4. Run the code and check if the algorithm is right (0 is unhappy, 1 is happy)!\n",
    "    \n",
    "The training/test sets were quite similar; for example, all the pictures were taken against the same background (since a front door camera is always mounted in the same position). This makes the problem easier, but a model trained on this data may or may not work on your own data. But feel free to give it a try! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img to array= (64, 64, 3) [[[196. 206. 145.]\n",
      "  [185. 157. 118.]\n",
      "  [177. 189. 151.]\n",
      "  ...\n",
      "  [249. 255. 181.]\n",
      "  [207. 227. 138.]\n",
      "  [255. 255. 226.]]\n",
      "\n",
      " [[171. 198. 117.]\n",
      "  [222. 240. 158.]\n",
      "  [157. 160. 117.]\n",
      "  ...\n",
      "  [249. 254. 196.]\n",
      "  [227. 242. 125.]\n",
      "  [254. 255. 197.]]\n",
      "\n",
      " [[187. 197. 145.]\n",
      "  [197. 211. 176.]\n",
      "  [235. 255. 195.]\n",
      "  ...\n",
      "  [218. 237. 145.]\n",
      "  [250. 255. 173.]\n",
      "  [253. 254. 210.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255. 255. 255.]\n",
      "  [115. 177.  68.]\n",
      "  [168. 217.  48.]\n",
      "  ...\n",
      "  [126. 148. 110.]\n",
      "  [101. 127.  90.]\n",
      "  [117. 134.  92.]]\n",
      "\n",
      " [[178. 176. 153.]\n",
      "  [127. 135.  58.]\n",
      "  [116. 142. 113.]\n",
      "  ...\n",
      "  [158. 158. 120.]\n",
      "  [167. 174. 123.]\n",
      "  [118. 139. 108.]]\n",
      "\n",
      " [[162. 141.  86.]\n",
      "  [155. 187. 146.]\n",
      "  [ 73.  77.  86.]\n",
      "  ...\n",
      "  [190. 170. 143.]\n",
      "  [178. 159. 127.]\n",
      "  [103. 118.  77.]]]\n",
      "expand dims  (1, 64, 64, 3) [[[[196. 206. 145.]\n",
      "   [185. 157. 118.]\n",
      "   [177. 189. 151.]\n",
      "   ...\n",
      "   [249. 255. 181.]\n",
      "   [207. 227. 138.]\n",
      "   [255. 255. 226.]]\n",
      "\n",
      "  [[171. 198. 117.]\n",
      "   [222. 240. 158.]\n",
      "   [157. 160. 117.]\n",
      "   ...\n",
      "   [249. 254. 196.]\n",
      "   [227. 242. 125.]\n",
      "   [254. 255. 197.]]\n",
      "\n",
      "  [[187. 197. 145.]\n",
      "   [197. 211. 176.]\n",
      "   [235. 255. 195.]\n",
      "   ...\n",
      "   [218. 237. 145.]\n",
      "   [250. 255. 173.]\n",
      "   [253. 254. 210.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255. 255. 255.]\n",
      "   [115. 177.  68.]\n",
      "   [168. 217.  48.]\n",
      "   ...\n",
      "   [126. 148. 110.]\n",
      "   [101. 127.  90.]\n",
      "   [117. 134.  92.]]\n",
      "\n",
      "  [[178. 176. 153.]\n",
      "   [127. 135.  58.]\n",
      "   [116. 142. 113.]\n",
      "   ...\n",
      "   [158. 158. 120.]\n",
      "   [167. 174. 123.]\n",
      "   [118. 139. 108.]]\n",
      "\n",
      "  [[162. 141.  86.]\n",
      "   [155. 187. 146.]\n",
      "   [ 73.  77.  86.]\n",
      "   ...\n",
      "   [190. 170. 143.]\n",
      "   [178. 159. 127.]\n",
      "   [103. 118.  77.]]]]\n",
      "preprocess (1, 64, 64, 3) [[[[ 41.060997   89.221      72.32     ]\n",
      "   [ 14.060997   40.221      61.32     ]\n",
      "   [ 47.060997   72.221      53.32     ]\n",
      "   ...\n",
      "   [ 77.061     138.22101   125.32     ]\n",
      "   [ 34.060997  110.221      83.32     ]\n",
      "   [122.061     138.22101   131.32     ]]\n",
      "\n",
      "  [[ 13.060997   81.221      47.32     ]\n",
      "   [ 54.060997  123.221      98.32     ]\n",
      "   [ 13.060997   43.221      33.32     ]\n",
      "   ...\n",
      "   [ 92.061     137.22101   125.32     ]\n",
      "   [ 21.060997  125.221     103.32     ]\n",
      "   [ 93.061     138.22101   130.32     ]]\n",
      "\n",
      "  [[ 41.060997   80.221      63.32     ]\n",
      "   [ 72.061      94.221      73.32     ]\n",
      "   [ 91.061     138.22101   111.32     ]\n",
      "   ...\n",
      "   [ 41.060997  120.221      94.32     ]\n",
      "   [ 69.061     138.22101   126.32     ]\n",
      "   [106.061     137.22101   129.32     ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[151.061     138.22101   131.32     ]\n",
      "   [-35.939003   60.221      -8.68     ]\n",
      "   [-55.939003  100.221      44.32     ]\n",
      "   ...\n",
      "   [  6.060997   31.221       2.3199997]\n",
      "   [-13.939003   10.221001  -22.68     ]\n",
      "   [-11.939003   17.221      -6.6800003]]\n",
      "\n",
      "  [[ 49.060997   59.221      54.32     ]\n",
      "   [-45.939003   18.221       3.3199997]\n",
      "   [  9.060997   25.221      -7.6800003]\n",
      "   ...\n",
      "   [ 16.060997   41.221      34.32     ]\n",
      "   [ 19.060997   57.221      43.32     ]\n",
      "   [  4.060997   22.221      -5.6800003]]\n",
      "\n",
      "  [[-17.939003   24.221      38.32     ]\n",
      "   [ 42.060997   70.221      31.32     ]\n",
      "   [-17.939003  -39.779     -50.68     ]\n",
      "   ...\n",
      "   [ 39.060997   53.221      66.32     ]\n",
      "   [ 23.060997   42.221      54.32     ]\n",
      "   [-26.939003    1.2210007 -20.68     ]]]]\n",
      "[[0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "img_path = 'images/my_image.jpg'\n",
    "### END CODE HERE ###\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "imshow(img)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "print('img to array=',x.shape ,x)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "print('expand dims ' ,x.shape, x)\n",
    "x = preprocess_input(x)\n",
    "print('preprocess' ,x.shape, x)\n",
    "\n",
    "print(happyModel.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(happyModel.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Other useful functions in Keras (Optional)\n",
    "\n",
    "Two other basic features of Keras that you'll find useful are:\n",
    "- `model.summary()`: prints the details of your layers in a table with the sizes of its inputs/outputs\n",
    "- `plot_model()`: plots your graph in a nice layout. You can even save it as \".png\" using SVG() if you'd like to share it on social media ;). It is saved in \"File\" then \"Open...\" in the upper bar of the notebook.\n",
    "\n",
    "Run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 70, 70, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 64, 64, 32)        4736      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool (MaxPooling2D)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 32769     \n",
      "=================================================================\n",
      "Total params: 37,633\n",
      "Trainable params: 37,569\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "happyModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 225.00 556.00\" width=\"225pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-552 221,-552 221,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2254968048776 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2254968048776</title>\n",
       "<polygon fill=\"none\" points=\"45.5,-511.5 45.5,-547.5 171.5,-547.5 171.5,-511.5 45.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-525.8\">input_4: InputLayer</text>\n",
       "</g>\n",
       "<!-- 2254968046424 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2254968046424</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 217,-474.5 217,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-452.8\">zero_padding2d_4: ZeroPadding2D</text>\n",
       "</g>\n",
       "<!-- 2254968048776&#45;&gt;2254968046424 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2254968048776-&gt;2254968046424</title>\n",
       "<path d=\"M108.5,-511.313C108.5,-503.289 108.5,-493.547 108.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"112,-484.529 108.5,-474.529 105,-484.529 112,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2254970543296 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2254970543296</title>\n",
       "<polygon fill=\"none\" points=\"56,-365.5 56,-401.5 161,-401.5 161,-365.5 56,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-379.8\">conv0: Conv2D</text>\n",
       "</g>\n",
       "<!-- 2254968046424&#45;&gt;2254970543296 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2254968046424-&gt;2254970543296</title>\n",
       "<path d=\"M108.5,-438.313C108.5,-430.289 108.5,-420.547 108.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"112,-411.529 108.5,-401.529 105,-411.529 112,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2254976915328 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2254976915328</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-292.5 31.5,-328.5 185.5,-328.5 185.5,-292.5 31.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-306.8\">bn0: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 2254970543296&#45;&gt;2254976915328 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2254970543296-&gt;2254976915328</title>\n",
       "<path d=\"M108.5,-365.313C108.5,-357.289 108.5,-347.547 108.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"112,-338.529 108.5,-328.529 105,-338.529 112,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2254976916112 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2254976916112</title>\n",
       "<polygon fill=\"none\" points=\"34.5,-219.5 34.5,-255.5 182.5,-255.5 182.5,-219.5 34.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-233.8\">activation_4: Activation</text>\n",
       "</g>\n",
       "<!-- 2254976915328&#45;&gt;2254976916112 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2254976915328-&gt;2254976916112</title>\n",
       "<path d=\"M108.5,-292.313C108.5,-284.289 108.5,-274.547 108.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"112,-265.529 108.5,-255.529 105,-265.529 112,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2254976916280 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2254976916280</title>\n",
       "<polygon fill=\"none\" points=\"26.5,-146.5 26.5,-182.5 190.5,-182.5 190.5,-146.5 26.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-160.8\">max_pool: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 2254976916112&#45;&gt;2254976916280 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2254976916112-&gt;2254976916280</title>\n",
       "<path d=\"M108.5,-219.313C108.5,-211.289 108.5,-201.547 108.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"112,-192.529 108.5,-182.529 105,-192.529 112,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2255103655888 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2255103655888</title>\n",
       "<polygon fill=\"none\" points=\"54,-73.5 54,-109.5 163,-109.5 163,-73.5 54,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-87.8\">flatten_4: Flatten</text>\n",
       "</g>\n",
       "<!-- 2254976916280&#45;&gt;2255103655888 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>2254976916280-&gt;2255103655888</title>\n",
       "<path d=\"M108.5,-146.313C108.5,-138.289 108.5,-128.547 108.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"112,-119.529 108.5,-109.529 105,-119.529 112,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2255104024024 -->\n",
       "<g class=\"node\" id=\"node8\"><title>2255104024024</title>\n",
       "<polygon fill=\"none\" points=\"74,-0.5 74,-36.5 143,-36.5 143,-0.5 74,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-14.8\">fc: Dense</text>\n",
       "</g>\n",
       "<!-- 2255103655888&#45;&gt;2255104024024 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2255103655888-&gt;2255104024024</title>\n",
       "<path d=\"M108.5,-73.3129C108.5,-65.2895 108.5,-55.5475 108.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"112,-46.5288 108.5,-36.5288 105,-46.5289 112,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(happyModel, to_file='HappyModel.png')\n",
    "SVG(model_to_dot(happyModel).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# here we check how images and its respected classes (o/p) are assigned for datasets from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: HappyModel\n",
    "\n",
    "def Happy1(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the HappyModel.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Feel free to use the suggested outline in the text above to get started, and run through the whole\n",
    "    # exercise (including the later portions of this notebook) once. The come back also try out other\n",
    "    # network architectures as well. \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (5, 5), strides=(1, 1), name='conv0')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    print(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(5, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs=X_input, outputs=X, name='Happy1')\n",
    "\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_5/Relu:0\", shape=(?, 66, 66, 32), dtype=float32)\n",
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "happy1 = Happy1(x1.shape[1:])\n",
    "print(x1.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1.62434536e+01 -6.11756414e+00 -5.28171752e+00]\n",
      "   [-1.07296862e+01  8.65407629e+00 -2.30153870e+01]\n",
      "   [ 1.74481176e+01 -7.61206901e+00  3.19039096e+00]\n",
      "   ...\n",
      "   [ 1.29322588e+01 -1.10447026e+00 -6.17362064e+00]\n",
      "   [ 5.62761097e+00  2.40737092e+00  2.80665077e+00]\n",
      "   [-7.31127037e-01  1.16033857e+01  3.69492716e+00]]\n",
      "\n",
      "  [[ 1.90465871e+01  1.11105670e+01  6.59049796e+00]\n",
      "   [-1.62743834e+01  6.02319280e+00  4.20282204e+00]\n",
      "   [ 8.10951673e+00  1.04444209e+01 -4.00878192e+00]\n",
      "   ...\n",
      "   [ 5.64382855e+00  2.13782807e+01 -7.85533997e+00]\n",
      "   [-1.75592564e+01  7.14789597e+00  8.52704062e+00]\n",
      "   [ 3.53600971e-01 -1.53879325e+01 -4.47895185e+00]]\n",
      "\n",
      "  [[ 6.17985534e+00 -1.84176326e+00 -1.15985185e+00]\n",
      "   [-1.75458969e+00 -9.33914656e+00 -5.33020326e+00]\n",
      "   [-1.42655542e+01  1.76795995e+01 -4.75372875e+00]\n",
      "   ...\n",
      "   [ 1.07343294e+00 -1.39881282e+01  8.17678188e-01]\n",
      "   [-4.59942831e+00  6.44353666e+00  3.71670291e+00]\n",
      "   [ 1.85300949e+01  1.42251373e+00  5.13505480e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.03019446e+01 -1.32090320e+01  1.66878154e+01]\n",
      "   [ 1.53726999e+01  7.12701562e+00 -1.13020607e+01]\n",
      "   [-8.89559787e+00 -9.82881743e+00 -7.18239121e+00]\n",
      "   ...\n",
      "   [-5.51978524e+00 -7.65183099e+00  2.93494989e+00]\n",
      "   [ 1.64633870e+00 -9.44652416e-01  5.59186631e+00]\n",
      "   [-5.17345126e+00  1.29284043e+01 -8.38202017e+00]]\n",
      "\n",
      "  [[ 1.28051506e+01 -5.45989230e+00  8.52857660e+00]\n",
      "   [ 6.83522927e-01  5.34016765e-01 -9.29342351e+00]\n",
      "   [ 1.38592029e+01 -2.60521903e+00  6.60987820e+00]\n",
      "   ...\n",
      "   [-5.86519938e+00 -1.73630294e+01  1.49520554e+01]\n",
      "   [ 1.02385201e+01 -5.14931427e+00 -2.13948881e+00]\n",
      "   [ 2.72699428e+00 -2.13691622e+01 -8.42251121e+00]]\n",
      "\n",
      "  [[-8.50232100e+00  8.00879718e+00  1.58483920e+01]\n",
      "   [ 6.35085690e-01 -1.08511556e+01 -5.07023136e+00]\n",
      "   [-1.56882748e+00  2.16701792e+01  5.94137788e+00]\n",
      "   ...\n",
      "   [-3.47411998e+00 -5.65180043e-01 -5.40690456e+00]\n",
      "   [-3.59411494e+00  7.42779792e+00 -1.65735869e+01]\n",
      "   [-5.27214195e+00 -3.80339666e+00  9.49412377e+00]]]\n",
      "\n",
      "\n",
      " [[[ 1.00923111e+01  2.29888995e+00 -6.64099097e+00]\n",
      "   [-4.22008953e+00 -1.40366346e+01  9.19541976e+00]\n",
      "   [-9.87500860e+00  1.16171714e+01  1.60963423e+01]\n",
      "   ...\n",
      "   [-2.64246967e+00 -3.75709030e+00 -8.44209845e+00]\n",
      "   [-2.76392428e+00 -1.59822826e+01  1.16536559e+01]\n",
      "   [ 2.17048791e+01  1.51333518e+01  6.02568829e+00]]\n",
      "\n",
      "  [[-5.11301687e+00  1.47640754e+01 -4.52517592e+00]\n",
      "   [-1.13232971e+01 -2.14556808e+00 -7.19951793e+00]\n",
      "   [-3.25305892e+00  1.47348889e+01  2.66726198e-01]\n",
      "   ...\n",
      "   [ 5.43830832e+00  9.02411818e-01  3.26674347e+00]\n",
      "   [-4.32222437e+00  4.66443084e+00  3.87278349e+00]\n",
      "   [-8.18986543e+00 -1.25878606e+01 -8.21538214e+00]]\n",
      "\n",
      "  [[ 4.27420904e+00 -6.78556610e+00  1.90841721e+01]\n",
      "   [ 9.11668631e+00  7.45671202e+00  1.02995153e+01]\n",
      "   [-3.80269316e+00 -8.16412662e+00 -1.02418416e+01]\n",
      "   ...\n",
      "   [-5.09865714e+00  1.98284648e+00  5.52987856e+00]\n",
      "   [ 2.12659601e+01 -5.53543609e+00  5.39847608e+00]\n",
      "   [ 6.23224026e+00 -1.31196075e+01 -6.65130861e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 6.96139352e+00  2.31154308e+01  1.03561473e+01]\n",
      "   [ 9.05268669e-01 -1.11042856e+01  4.92133308e+00]\n",
      "   [-4.55282998e+00 -3.03386296e+00  1.15876993e+01]\n",
      "   ...\n",
      "   [-1.40472001e+01  8.99303199e+00  8.52197815e+00]\n",
      "   [-2.84612867e+01  1.50625931e+01 -5.29672580e+00]\n",
      "   [-5.73659258e+00  8.91562196e+00  2.55572381e+00]]\n",
      "\n",
      "  [[ 2.94893677e+00  6.25173877e+00 -5.31829628e-01]\n",
      "   [ 9.77488505e+00  1.09680235e+01 -2.85730582e+00]\n",
      "   [ 1.09453897e+01 -6.58888436e+00  1.49269197e+01]\n",
      "   ...\n",
      "   [ 1.65380316e+00  6.02015680e+00 -4.96039827e+00]\n",
      "   [-5.22781273e-01  1.13407264e+01 -1.13301519e+01]\n",
      "   [-1.05834743e+00  1.13689963e+01 -8.42008404e+00]]\n",
      "\n",
      "  [[ 1.35882684e+01 -5.69493416e+00  3.78430242e+00]\n",
      "   [-2.53771436e+00 -1.31785220e+01  2.55347783e+00]\n",
      "   [ 7.77673796e+00  1.93877827e+01 -6.48223083e+00]\n",
      "   ...\n",
      "   [-3.21742951e-01  1.11782107e+01 -9.34774896e+00]\n",
      "   [ 1.07172693e+01  7.37795833e+00  1.12383092e+01]\n",
      "   [ 6.89858854e+00 -4.88322043e+00  2.07609724e+00]]]\n",
      "\n",
      "\n",
      " [[[-3.56339799e+00 -1.95480834e+00  6.36802728e+00]\n",
      "   [ 1.12679494e+01  2.24199955e+01  3.55011660e+00]\n",
      "   [-5.47176079e+00  2.89018121e+00  4.39454608e+00]\n",
      "   ...\n",
      "   [ 5.32406176e+00 -1.74821358e+01  7.36835476e+00]\n",
      "   [-3.20859741e+00 -5.40207335e+00 -4.11879387e+00]\n",
      "   [-8.98191553e+00 -4.84826979e+00 -1.48875904e+01]]\n",
      "\n",
      "  [[-8.62594653e+00 -2.60007005e+01 -3.73846510e+00]\n",
      "   [-5.07860135e+00  3.08061479e+00 -6.50799346e+00]\n",
      "   [ 6.65965799e+00  2.16779398e+00  3.08709704e+00]\n",
      "   ...\n",
      "   [-5.93169433e+00 -1.16485734e+01 -3.70927921e+00]\n",
      "   [-9.57437821e-01 -1.80216951e-01  1.40630823e+01]\n",
      "   [ 1.50196053e+01  8.28891694e+00 -1.20200614e+01]]\n",
      "\n",
      "  [[ 7.81968990e+00 -5.76577714e+00  5.70598056e+00]\n",
      "   [ 1.24611435e+00 -4.26606195e+00  8.81925194e+00]\n",
      "   [ 1.29409397e+01 -1.24191894e+01  1.23531238e+00]\n",
      "   ...\n",
      "   [ 1.45204149e+01 -3.68591402e+00 -7.80889438e-01]\n",
      "   [ 3.93016800e-01  2.82061137e+00  3.37214827e+00]\n",
      "   [-1.16615395e+01  1.38560804e+01 -1.03955923e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.83372874e+01 -2.36732684e-01  1.72205716e+01]\n",
      "   [-2.04390292e+01 -1.30949792e+00  9.86750914e+00]\n",
      "   [-7.31153546e+00  2.71944022e+00 -9.15882513e+00]\n",
      "   ...\n",
      "   [-7.75221509e+00 -6.64313119e+00 -1.10335985e-01]\n",
      "   [ 1.50882309e+00 -6.63833801e+00 -6.09955275e+00]\n",
      "   [-4.34132587e+00 -2.01885030e+00 -1.42827770e+01]]\n",
      "\n",
      "  [[-9.36324577e+00 -2.52826716e+00  1.13557804e+01]\n",
      "   [ 9.06941607e+00  3.29360387e-01  1.03021678e+01]\n",
      "   [ 1.25632794e+01 -3.40318843e+00 -8.82816745e+00]\n",
      "   ...\n",
      "   [ 5.78584531e+00 -9.84907442e+00  2.22261744e+01]\n",
      "   [ 1.10833495e+01  4.38864468e+00  2.18644375e+01]\n",
      "   [-2.72986564e+00  1.46300843e+01  6.76733306e+00]]\n",
      "\n",
      "  [[-6.12015140e+00 -1.05297200e-01  1.12954794e+01]\n",
      "   [-7.11676529e+00  1.82739525e+01  4.37193447e+00]\n",
      "   [-1.18055010e+00 -6.48354804e+00 -1.18974696e+01]\n",
      "   ...\n",
      "   [-1.79582245e+01  5.26644042e+00 -1.23883536e+01]\n",
      "   [-4.32685390e+00 -2.31468814e+00  4.48966945e-01]\n",
      "   [ 8.22751365e+00 -1.04425246e+00 -6.57956716e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-2.20155674e-01  1.03969994e+01 -5.96365769e+00]\n",
      "   [ 1.00172516e+01  9.81668644e+00  3.57232117e+00]\n",
      "   [-1.59088803e-02  1.67722750e+00  9.25216440e-01]\n",
      "   ...\n",
      "   [-4.15778251e+00 -1.64214407e+01  6.64527019e+00]\n",
      "   [ 1.75851736e+01 -1.10041139e+01  1.97608303e+01]\n",
      "   [ 4.09503503e+00  9.47260496e+00 -2.97843365e+00]]\n",
      "\n",
      "  [[ 8.60064997e-01  8.08514374e+00 -4.48992413e-01]\n",
      "   [ 2.01115468e+00  8.41986781e+00  1.03340440e+01]\n",
      "   [-1.18453805e+01 -1.63612010e+00  5.48253876e+00]\n",
      "   ...\n",
      "   [-5.73657339e+00 -2.77446802e+00  4.30842454e-01]\n",
      "   [ 4.93743948e+00  1.06727236e+01 -1.03113237e+01]\n",
      "   [ 3.04028511e+00  1.46925424e+00  9.81591834e-01]]\n",
      "\n",
      "  [[-9.23043115e+00  6.67624450e+00 -1.24503161e+01]\n",
      "   [-1.66352550e+00  1.03728973e+01 -5.22170745e-01]\n",
      "   [ 2.24401252e+00 -3.37080095e+00  3.80697134e+00]\n",
      "   ...\n",
      "   [ 7.89296045e+00  3.04726043e+00  1.48807477e+01]\n",
      "   [ 1.25816123e+00 -2.51280269e+00 -2.81841821e+00]\n",
      "   [ 1.23270787e+01 -7.02674911e+00 -7.47940224e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 6.19348861e+00 -4.67815178e+00  6.26666379e+00]\n",
      "   [ 1.24630088e+01 -1.54938685e+01 -1.24429346e+00]\n",
      "   [-1.41001571e+01 -3.32565081e-01  3.38546265e+00]\n",
      "   ...\n",
      "   [-4.91556110e+00 -1.27894032e+00  9.50758265e+00]\n",
      "   [-6.96963671e+00  3.26841330e+00  7.94847730e+00]\n",
      "   [-2.63762133e+00  9.68193141e+00  3.42265555e+00]]\n",
      "\n",
      "  [[-2.98960076e+00 -7.78416263e+00  6.55080975e+00]\n",
      "   [-3.25640763e+00 -7.70625517e+00 -1.23446703e+01]\n",
      "   [ 2.47620558e+00 -2.00038795e+01  1.87278919e+01]\n",
      "   ...\n",
      "   [-9.13133577e+00  3.53713681e+00 -3.43410464e+00]\n",
      "   [-6.83047533e+00 -1.58952562e+00 -2.68878342e+00]\n",
      "   [-1.07384412e+01 -8.82870664e+00 -3.08422296e-01]]\n",
      "\n",
      "  [[ 9.05842913e+00  1.35447279e-01  2.48944545e+01]\n",
      "   [-1.31760343e+01  2.16960535e+01 -2.04405687e+01]\n",
      "   [-1.95375862e+00  1.60180345e+00 -1.63004718e+01]\n",
      "   ...\n",
      "   [-1.71474932e+01  1.93940012e+00 -7.03494474e+00]\n",
      "   [-1.24356462e+01  2.68883835e+00  6.94668308e+00]\n",
      "   [-2.21903934e-01  4.33022100e+00  4.90017716e+00]]]\n",
      "\n",
      "\n",
      " [[[-2.83065690e+01 -1.57564670e+00  6.16140659e+00]\n",
      "   [-8.32240858e+00  2.02388864e+00  6.73153325e-01]\n",
      "   [ 4.06039785e+00 -2.46330692e+00 -1.94336908e+01]\n",
      "   ...\n",
      "   [-9.07496792e+00 -4.09180671e+00  2.16093825e+00]\n",
      "   [ 1.23300360e+01  1.09548836e+01  2.63917892e+00]\n",
      "   [ 1.02087485e+01 -7.11484629e+00 -9.15410379e+00]]\n",
      "\n",
      "  [[ 6.40553685e+00  1.92206269e+01  9.98208221e+00]\n",
      "   [ 1.72643152e+01 -1.40251224e+01 -9.82743209e+00]\n",
      "   [ 6.56816866e+00  5.45930531e+00  1.57639933e+01]\n",
      "   ...\n",
      "   [-4.89916918e+00  6.09763811e+00 -1.26029759e+01]\n",
      "   [-7.33497322e+00  1.51549355e+01 -1.05607537e+01]\n",
      "   [ 5.20081993e+00  7.76211590e+00  3.04080360e-01]]\n",
      "\n",
      "  [[ 1.22160287e+01  2.61711696e-01 -2.49562781e+01]\n",
      "   [ 1.26800667e+00 -3.21451185e+00  7.77373266e+00]\n",
      "   [-1.94519589e+00 -1.52733405e+01 -1.94915436e+00]\n",
      "   ...\n",
      "   [ 8.78212065e+00 -8.14467670e+00 -3.38504009e+00]\n",
      "   [ 8.53239215e-01  7.58850283e+00 -1.57433247e+00]\n",
      "   [-9.82521929e+00  7.57886714e+00  6.13231724e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-6.37767601e+00 -1.73279455e+01 -1.14047786e+00]\n",
      "   [ 3.11196732e+00 -1.14267349e+01  1.32704942e+01]\n",
      "   [-1.04575148e+01 -1.84313949e+00  1.21852568e-01]\n",
      "   ...\n",
      "   [ 3.94034110e+00  1.27732757e+01  1.29179852e+01]\n",
      "   [-1.09745740e+01  8.58567170e-01  1.17574952e+01]\n",
      "   [ 1.68730568e+01  1.77208279e+01  3.62508573e+00]]\n",
      "\n",
      "  [[ 7.13094078e+00 -1.06955734e+01 -1.40708055e+01]\n",
      "   [ 1.42197144e+00  2.29749801e+00 -9.78673582e+00]\n",
      "   [-1.37354118e+01  1.87668950e-01  1.63642874e+01]\n",
      "   ...\n",
      "   [ 8.32034699e+00  6.23952289e+00  4.09145688e+00]\n",
      "   [ 1.68060692e+00 -7.82757898e+00 -1.42849890e+01]\n",
      "   [-6.13543911e+00 -2.70117819e+00 -1.61340921e+00]]\n",
      "\n",
      "  [[ 4.48064568e+00  7.61787400e+00  4.48469937e-01]\n",
      "   [ 1.36961914e+01  4.15585157e+00 -4.38132069e+00]\n",
      "   [ 5.75604275e+00  3.50685338e+00  2.66057357e+01]\n",
      "   ...\n",
      "   [-1.04742412e+00 -1.10481258e+01 -5.17454846e+00]\n",
      "   [ 2.12782792e+00 -2.63465672e+01  6.71435967e-01]\n",
      "   [-1.48793988e+01  3.00034553e+00 -1.85304991e+01]]]\n",
      "\n",
      "\n",
      " [[[-8.41909939e+00  7.92512616e+00  3.24663130e+00]\n",
      "   [-7.27321292e+00 -9.93012923e+00  3.58351323e-01]\n",
      "   [-2.76409603e+00 -4.24560365e+00 -1.50554478e+01]\n",
      "   ...\n",
      "   [ 5.20199636e-02 -4.25675403e+00  7.21392693e+00]\n",
      "   [ 8.68771986e+00  1.26094213e+01 -1.81624665e+01]\n",
      "   [-2.68593007e+00  8.41023990e+00 -6.25710524e-01]]\n",
      "\n",
      "  [[ 1.01131574e+00 -1.43924427e+01  8.60895817e+00]\n",
      "   [ 1.70466444e+01  5.87770963e+00 -1.90940965e-01]\n",
      "   [-9.05389830e+00  1.65766665e+01  2.04942461e+00]\n",
      "   ...\n",
      "   [ 1.02511635e+00  6.87378384e-01  1.42888611e+01]\n",
      "   [ 1.98638218e+01 -6.02906775e+00 -1.34163343e+01]\n",
      "   [-8.28038395e+00 -9.71929585e+00  1.26149629e+01]]\n",
      "\n",
      "  [[-3.45056193e+00 -5.48436285e+00  1.00239989e+01]\n",
      "   [-8.19771524e+00 -7.83912965e-01  6.38054166e+00]\n",
      "   [-1.14695467e+01 -9.13207562e+00  2.88894528e+00]\n",
      "   ...\n",
      "   [ 1.06951264e+01 -1.34011175e+01  1.44699272e+01]\n",
      "   [ 2.88847527e+00 -2.75653642e+00  7.14249270e+00]\n",
      "   [ 1.10074440e+01 -8.03750502e+00  1.24733543e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.02278409e+01  1.08078327e+01  1.79804142e+01]\n",
      "   [ 3.17011472e+00 -1.26306086e+01 -7.82465842e+00]\n",
      "   [ 6.44186972e+00 -7.79208379e+00 -1.20730856e+01]\n",
      "   ...\n",
      "   [ 1.27420999e+00  1.92873563e+00  5.29738895e+00]\n",
      "   [ 1.60870015e+01  2.02527202e+00  1.06863986e+01]\n",
      "   [-2.63407743e+00 -8.03339887e+00 -2.07051453e+00]]\n",
      "\n",
      "  [[ 3.53025685e+00  8.12983736e+00 -7.67458106e+00]\n",
      "   [ 1.15926404e+01  1.33820505e+01  9.56991259e+00]\n",
      "   [-4.30206334e+00 -8.95651996e+00  5.56297188e+00]\n",
      "   ...\n",
      "   [ 6.28438368e+00  4.74952977e-01  5.40543453e+00]\n",
      "   [ 5.43172578e+00  1.55715781e+01 -5.53899550e+00]\n",
      "   [ 7.32057231e-01 -2.10073242e+01 -9.04176759e+00]]\n",
      "\n",
      "  [[ 1.37329211e+00 -8.76094982e+00 -7.63801786e+00]\n",
      "   [-3.13878669e+00  2.00979359e+00  8.54866776e+00]\n",
      "   [-8.80681173e+00 -1.13438591e+01  1.16277602e+01]\n",
      "   ...\n",
      "   [ 5.78156512e+00 -3.82103322e+00  1.63882781e+00]\n",
      "   [-5.82179044e+00  1.06803122e+01  1.95490963e+01]\n",
      "   [-1.31894788e+01  1.11760265e+01  2.56195257e+00]]]] [[0]\n",
      " [1]\n",
      " [3]\n",
      " [0]\n",
      " [4]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [3]\n",
      " [2]\n",
      " [0]\n",
      " [4]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [3]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [3]\n",
      " [0]\n",
      " [3]\n",
      " [1]\n",
      " [3]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [3]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "x1 = np.random.randn(50,64,64,3)*10\n",
    "#x1 = x1/\n",
    "y1 = np.array([[0,1,3,0,4,0,2,1,2,3,2,1,2,0,1,0,1,1,3,2,0,4,1,2,1,1,3,1,0,2,0,2,1,0,3,0,3,1,3,1,0,1,3,0,1,0,1,1,0,1]]).T\n",
    "#y1 = y1.reshape(10,1).T\n",
    "print(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y,c):\n",
    "    out = np.eye(c)[y.reshape(-1)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = one_hot(y1,c=5)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy1.compile('adam' , 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600: 0s - loss: 11.0524 - acc: 0.31\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600 ETA: 0s - loss: 10.1314 - acc: 0.3714  \n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 10.3156 - acc: 0.3600\n"
     ]
    }
   ],
   "source": [
    "model1 = happy1.fit(x1,out,epochs=20,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "model1 = happy1.evaluate(x1,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy1.predict(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
